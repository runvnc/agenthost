llama_new_context_with_model: n_ctx      = 4096                                                                                  
llama_new_context_with_model: freq_base  = 1000000.0                                                                             
llama_new_context_with_model: freq_scale = 1                                                                                     
llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB                            
llama_build_graph: non-view tensors processed: 1124/1124                                                                         
llama_new_context_with_model: compute buffer total size = 319.35 MiB                                                             
                                                                                                                                 
system_info: n_threads = 10 / 20 | AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM
_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 |                                  
sampling:                                                                                                                        
        repeat_last_n = 64, repeat_penalty = 1.000, frequency_penalty = 0.000, presence_penalty = 0.000                          
        top_k = 40, tfs_z = 1.000, top_p = 0.950, min_p = 0.050, typical_p = 1.000, temp = 0.000                                 
        mirostat = 0, mirostat_lr = 0.100, mirostat_ent = 5.000                                                                  
sampling order:                                                                                                                  
CFG -> Penalties -> top_k -> tfs_z -> typical_p -> top_p -> min_p -> temp                                                        
generate: n_ctx = 4096, n_batch = 512, n_predict = -1, n_keep = 0   
